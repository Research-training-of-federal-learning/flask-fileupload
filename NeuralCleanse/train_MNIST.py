import torch
import numpy as np
from torch.nn import CrossEntropyLoss
import tqdm
from torch.utils.data import DataLoader, TensorDataset
import matplotlib.pyplot as plt
from NeuralCleanse.data import get_data
from NeuralCleanse.mymodel.GTSRB import GTSRBNet
from torchvision import datasets, transforms
from NeuralCleanse.mymodel.model import Model
import torch.nn as nn
import torch.nn.functional as F


def train(model, target_label, train_loader, param):
    print("Processing label: {}".format(target_label))

    width, height = param["image_size"]
    trigger = torch.rand((1, width, height), requires_grad=True)
    trigger = trigger.to(device).detach().requires_grad_(True)
    mask = torch.rand((width, height), requires_grad=True)
    mask = mask.to(device).detach().requires_grad_(True)

    Epochs = param["Epochs"]
    lamda = param["lamda"]

    min_norm = np.inf
    min_norm_count = 0

    criterion = CrossEntropyLoss()
    optimizer = torch.optim.Adam([{"params": trigger}, {"params": mask}], lr=0.005)
    model.to(device)
    model.eval()

    for epoch in range(Epochs):
        norm = 0.0
        # norm_classes = [0. for j in range(43)]
        for images, targets in tqdm.tqdm(train_loader, desc='Epoch %3d' % (epoch + 1)):
            optimizer.zero_grad()
            images = images.to(device)
            trojan_images = (1 - torch.unsqueeze(mask, dim=0)) * images + torch.unsqueeze(mask, dim=0) * trigger
            # print(trojan_images)
            y_pred = model(trojan_images)
            y_target = torch.full((y_pred.size(0),), target_label, dtype=torch.long).to(device)
            loss = criterion(y_pred, y_target) + lamda * torch.sum(torch.abs(mask))
            loss.backward()
            optimizer.step()

            # figure norm
            with torch.no_grad():
                # 防止trigger和norm越界
                torch.clip_(trigger, 0, 1)
                torch.clip_(mask, 0, 1)
                norm = torch.sum(torch.abs(mask))
                # norm_classes[] = torch.sum(torch.abs(mask))
        print("norm: {}".format(norm))

        # to early stop
        if norm < min_norm:
            min_norm = norm
            min_norm_count = 0
        else:
            min_norm_count += 1

        if min_norm_count > 30:
            break

    return trigger.cpu(), mask.cpu()


# LeNet Model definition
class Net(Model):  # 创建网络
    def __init__(self, num_classes):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5, 1)
        self.conv2 = nn.Conv2d(20, 50, 5, 1)
        self.fc1 = nn.Linear(4 * 4 * 50, 500)
        self.fc2 = nn.Linear(500, num_classes)

    def features(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2, 2)
        return x

    def forward(self, x, latent=False):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2, 2)
        if x.requires_grad:
            x.register_hook(self.activations_hook)
        x = x.view(-1, 4 * 4 * 50)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        out = F.log_softmax(x, dim=1)
        if latent:
            return out, x
        else:
            return out

def printSuperMerry():
    print('''
                    ********
                   ************
                   ####....#.
                 #..###.....##....
                 ###.......######              ###            ###
                    ...........               #...#          #...#
                   ##*#######                 #.#.#          #.#.#
                ####*******######             #.#.#          #.#.#
               ...#***.****.*###....          #...#          #...#
               ....**********##.....           ###            ###
               ....****    *****....
                 ####        ####
               ######        ######
    ##############################################################
    #...#......#.##...#......#.##...#......#.##------------------#
    ###########################################------------------#
    #..#....#....##..#....#....##..#....#....#####################
    ##########################################    #----------#
    #.....#......##.....#......##.....#......#    #----------#
    ##########################################    #----------#
    #.#..#....#..##.#..#....#..##.#..#....#..#    #----------#
    ##########################################    ############
    ''')

def reverse_engineer():
    printSuperMerry()
    param = {
        "dataset": "MNIST",
        "Epochs": 10,
        "batch_size": 64,
        "lamda": 0.01,
        "num_classes": 10,
        "image_size": (28, 28)
    }
    classes = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)
    model = Net(10).to(device)
    model.load_state_dict(torch.load('NeuralCleanse/MNIST_model_last.pt.tar')['state_dict'])  # 导入数据
    # model = torch.load('model_cifar10.pkl').to(device)
    # _, _, x_test, y_test = get_data(param)
    # x_test, y_test = torch.from_numpy(x_test)/255., torch.from_numpy(y_test)
    # train_loader = DataLoader(TensorDataset(x_test, y_test), batch_size=param["batch_size"], shuffle=False)
    train_loader = torch.utils.data.DataLoader(  # 导入数据
        datasets.MNIST('../data',# 切记 要从app.py为基准做相对路径
                       train=False,
                       download=True,  # 下载
                       transform=transforms.Compose([
                           transforms.ToTensor(),
                       ])),
        batch_size=param["batch_size"], shuffle=False)

    norm_list = []
    for label in range(param["num_classes"]):  # 每一类进行训练
        trigger, mask = train(model, label, train_loader, param)
        norm_list.append(mask.sum().item())

        trigger = trigger.cpu().detach().numpy()
        # trigger = np.transpose(trigger, (1,2,0))
        plt.axis("off")
        plt.imshow(trigger.squeeze(), cmap="gray")
        plt.savefig('NeuralCleanse/mask_MNIST/trigger_{}.png'.format(label), bbox_inches='tight', pad_inches=0.0)

        mask = mask.cpu().detach().numpy()
        plt.axis("off")
        plt.imshow(mask, cmap="gray")
        plt.savefig('NeuralCleanse/mask_MNIST/mask_{}.png'.format(label), bbox_inches='tight', pad_inches=0.0)

    print(norm_list)


if __name__ == "__main__":
    print("gpu is available:")
    print(torch.cuda.is_available())
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    reverse_engineer()
